{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BgvPpHvfzxGd"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with 'Python 3.14.0' requires the ipykernel package.\n",
            "\u001b[1;31m<a href='command:jupyter.createPythonEnvAndSelectController'>Create a Python Environment</a> with the required packages.\n",
            "\u001b[1;31mOr install 'ipykernel' using the command: 'c:/Users/HP/AppData/Local/Programs/Python/Python314/python.exe -m pip install ipykernel -U --user --force-reinstall'"
          ]
        }
      ],
      "source": [
        "# datatec.studio\n",
        "!pip -qqq install bitsandbytes accelerate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tFQgZK5HDWoW"
      },
      "outputs": [],
      "source": [
        "with open('companyProfile.txt', 'r') as file:\n",
        "    file_content = file.read()\n",
        "print(file_content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kWHZEwhmy7m6"
      },
      "outputs": [],
      "source": [
        "import transformers\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-nbeK8hGzI4o"
      },
      "outputs": [],
      "source": [
        "model_id = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
        "\n",
        "pipeline = transformers.pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model_id,\n",
        "    model_kwargs={\"torch_dtype\": torch.bfloat16},\n",
        "    device_map=\"auto\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mDWcsVegAgrt"
      },
      "outputs": [],
      "source": [
        "def chat(user_question):\n",
        "\n",
        "    messages = [\n",
        "      {\"role\": \"system\", \"content\": \"Please answer questions just based on this information: \" + file_content},\n",
        "      {\"role\": \"user\", \"content\": user_question},\n",
        "    ]\n",
        "\n",
        "    prompt = pipeline.tokenizer.apply_chat_template(\n",
        "            messages,\n",
        "            tokenize=False,\n",
        "            add_generation_prompt=True\n",
        "    )\n",
        "\n",
        "    terminators = [\n",
        "        pipeline.tokenizer.eos_token_id,\n",
        "        pipeline.tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n",
        "    ]\n",
        "\n",
        "    outputs = pipeline(\n",
        "        prompt,\n",
        "        max_new_tokens=256,\n",
        "        eos_token_id=terminators,\n",
        "        do_sample=True,\n",
        "        temperature=0.6,\n",
        "        top_p=0.9,\n",
        "    )\n",
        "    return (outputs[0][\"generated_text\"][len(prompt):])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XMbcKKbU3WnX"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "while True:\n",
        "    # Ask questions to chatbot\n",
        "    # Do you know company Dummy-Gpt2-Datatec-Studio Inc?\n",
        "    # Which products does Dummy-Gpt2-Datatec-Studio Inc have?\n",
        "    question = input(\"Please enter your question (or 'quit' to stop): \")\n",
        "    if question.lower() == 'quit':\n",
        "        break\n",
        "    response = chat(question)\n",
        "    print(response)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h5yQTsmFIAGL"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.14.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
